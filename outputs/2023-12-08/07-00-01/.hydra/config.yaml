_target_: src.training.tasks.common_training_task.CommonTrainingTask
name: BinaryTextClassification
data_module:
  _target_: src.data_modules.data_modules.TextClassificationDataModule
  batch_size: 64
  shuffle: false
  num_workers: 8
  pin_memory: true
  drop_last: true
  persistent_workers: false
  train_df_path: gs://cyberbully_r/data/processed/default_run/train.parquet
  dev_df_path: gs://cyberbully_r/data/processed/default_run/dev.parquet
  test_df_path: gs://cyberbully_r/data/processed/default_run/test.parquet
  transformation: ${..lightning_module.model.backbone.transformation}
  text_column_name: cleaned_text
  label_column_name: label
lightning_module:
  _target_: src.training.lightning_modules.binary_text_classification.BinaryTextClassificationTrainingLightningModule
  model:
    _target_: src.models.models.BinaryTextClassificationModel
    backbone:
      _target_: src.models.backbones.HuggingFaceBackbone
      transformation:
        _target_: src.data_modules.transformations.HuggingFaceTokenizationTransformation
        pretrained_tokenizer_name_or_path: gs://cyberbully_r/data/processed/default_run/trained_tokenizer
        max_sequence_length: 100
      pretrained_model_name_or_path: prajjwal1/bert-tiny
      pretrained: false
    adapter:
      _target_: src.models.adapters.MLPWithPooling
      output_feature_sizes:
      - -1
      biases: null
      activation_fns: null
      dropout_drop_probs: null
      batch_norms: null
      order: LABDN
      standardize_input: true
      pooling_method: null
      output_attribute_to_use: pooler_output
    head:
      _target_: src.models.heads.SigmoidHead
      in_features: 128
      out_features: 1
  loss:
    _target_: src.training.loss_functions.BCEWithLogitsLoss
    reduction: mean
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 5.0e-05
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
    weight_decay: 0.001
    amsgrad: false
    foreach: null
    maximize: false
    capturable: false
  scheduler:
    _target_: src.training.schedulers.CommonLightningScheduler
    scheduler:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      _partial_: true
      mode: max
      factor: 0.1
      patience: 5
      threshold: 0.0001
      threshold_mode: rel
      cooldown: 0
      min_lr: 0.0
      eps: 1.0e-08
      verbose: false
    interval: epoch
    frequency: 1
    monitor: validation_f1_score
    strict: true
    name: null
trainer:
  _target_: lightning.pytorch.trainer.trainer.Trainer
  accelerator: gpu
  strategy: ddp_find_unused_parameters_true
  devices: auto
  num_nodes: 1
  precision: 16-mixed
  logger:
  - _target_: lightning.pytorch.loggers.mlflow.MLFlowLogger
    experiment_name: ${infrastructure.mlflow.experiment_name}
    run_name: ${infrastructure.mlflow.run_name}
    tracking_uri: ${infrastructure.mlflow.mlflow_internal_tracking_uri}
    tags: null
    save_dir: null
    prefix: ''
    artifact_location: null
    run_id: ${infrastructure.mlflow.run_id}
  callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${infrastructure.mlflow.artifact_uri}/best-checkpoints/
    filename: null
    monitor: validation_f1_score
    verbose: false
    save_last: true
    save_top_k: 2
    mode: max
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${infrastructure.mlflow.artifact_uri}/last-checkpoints/
    filename: checkpoint-{epoch}
    monitor: null
    verbose: false
    save_last: true
    save_top_k: -1
    mode: min
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: ${save_last_checkpoint_every_n_train_steps}
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step
  fast_dev_run: false
  max_epochs: 3
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: 0.01
  limit_val_batches: 0.01
  limit_test_batches: 0.01
  limit_predict_batches: 1.0
  overfit_batches: 0.0
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 2
  log_every_n_steps: 1
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  accumulate_grad_batches: 1
  gradient_clip_val: 5.0
  gradient_clip_algorithm: value
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  detect_anomaly: false
  barebones: false
  sync_batchnorm: true
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: ./data/pytorch-lightning
best_training_checkpoint: ${infrastructure.mlflow.artifact_uri}/best-checkpoints/last.ckpt
last_training_checkpoint: ${infrastructure.mlflow.artifact_uri}/last-checkpoints/last.ckpt
